{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file created: comprehensive_predictions_summary_3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'comprehensive_predictions_summary_3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function to extract mean value from the string\n",
    "def extract_mean(value):\n",
    "    return float(value.split(' ± ')[0])\n",
    "\n",
    "# Apply the function to relevant columns to get mean values\n",
    "data['Accuracy_mean'] = data['Accuracy'].apply(extract_mean)\n",
    "data['Prediction_Size_90_mean'] = data['Prediction Size (90% Coverage)'].apply(extract_mean)\n",
    "data['Coverage_90_mean'] = data['90% Coverage'].apply(extract_mean)\n",
    "\n",
    "# Save the updated CSV\n",
    "updated_file_path = 'comprehensive_predictions_summary_citeseer.csv'\n",
    "data.to_csv(updated_file_path, index=False)\n",
    "print(f\"Updated CSV file created: {updated_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created: comprehensive_predictions_summary_citeseer.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_values(line):\n",
    "    pattern = r\"Result: \\((\\d+), \\{'Accuracy': ([\\d.]+), 'APS': \\(([\\d.]+), ([\\d.]+)\\), 'APSeps05': \\(([\\d.]+), ([\\d.]+)\\)\\}\\)\"\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        result_num = int(match.group(1))\n",
    "        accuracy = float(match.group(2))\n",
    "        coverage_90 = float(match.group(3))\n",
    "        aps_score = float(match.group(4))\n",
    "        coverage_95 = float(match.group(5))\n",
    "        apseps05_score = float(match.group(6))\n",
    "        return result_num, accuracy, coverage_90, aps_score, coverage_95, apseps05_score\n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract values from line: {line}\")\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.replace('.txt', '').split('_')\n",
    "    \n",
    "    # Determine if the dataset is biased or unbiased\n",
    "    dataset_type = 'biased' if 'train' in parts else 'unbiased'\n",
    "    \n",
    "    data = {\n",
    "        'dataset_type': dataset_type,\n",
    "        'dataset': '',\n",
    "        'model': '',\n",
    "        'conformal_score': '',\n",
    "        'method': 'CE',  # Default method\n",
    "        'alpha_bias': '0.1' if dataset_type == 'biased' else '1.0',  # Default for biased datasets if not specified\n",
    "        'ld1': '0',  # Default value for ld1\n",
    "        'ld2': '0'  # Default value for ld2\n",
    "    }\n",
    "    \n",
    "    for i, part in enumerate(parts):\n",
    "        if part in ['cora', 'citeseer', 'PubMed']:\n",
    "            data['dataset'] = part\n",
    "        elif part in ['APPNP', 'GAT', 'GCN', 'GraphSAGE', 'DAGNN']:\n",
    "            data['model'] = part\n",
    "        elif part in ['aps', 'raps']:\n",
    "            data['conformal_score'] = part\n",
    "        elif part in ['SRGNN', 'cmd', 'MMD', 'CEMD', 'CKLJS', 'CKLJSEM', 'CKL', 'CJS', 'kld', 'jsd', 'emd', 'CE']:\n",
    "            data['method'] = part\n",
    "        elif part == 'alpha' and i + 1 < len(parts) and parts[i + 1] == 'bias':\n",
    "            data['alpha_bias'] = parts[i + 2]\n",
    "        elif part == 'ld1' and i + 1 < len(parts):\n",
    "            data['ld1'] = parts[i + 1]\n",
    "        elif part == 'ld2' and i + 1 < len(parts):\n",
    "            data['ld2'] = parts[i + 1]\n",
    "    \n",
    "    # Determine the method based on the dataset type and filename pattern\n",
    "    if dataset_type == 'unbiased':\n",
    "        data['method'] = 'IID'\n",
    "    elif dataset_type == 'biased' and 'ld1' in parts and 'ld2' in parts and data['method'] == 'CE':\n",
    "        data['method'] = 'biased(CE)'\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_files(folder_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                lines = content.strip().split('\\n')\n",
    "                values = [extract_values(line) for line in lines if line.strip()]\n",
    "                \n",
    "                if values:\n",
    "                    _, *metric_values = zip(*values)\n",
    "                    means = np.mean(metric_values, axis=1)\n",
    "                    stds = np.std(metric_values, axis=1)\n",
    "                    result = [f\"{mean:.4f} ± {std:.4f}\" for mean, std in zip(means, stds)]\n",
    "                    \n",
    "                    file_info = parse_filename(filename)\n",
    "                    data.append(list(file_info.values()) + result)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_csv(data, output_file):\n",
    "    columns = ['Dataset Type', 'Dataset', 'Model', 'Conformal Score', 'Method', 'Alpha Bias', 'LD1', 'LD2',\n",
    "               'Accuracy', '90% Coverage', 'Prediction Size (90% Coverage)', '95% Coverage', 'Prediction Size (95% Coverage)']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"CSV file created: {output_file}\")\n",
    "\n",
    "# Usage\n",
    "folder_path = r'D:\\csr\\CondSR\\pred_c'  # Using raw string for Windows path\n",
    "output_file = 'comprehensive_predictions_summary_citeseer.csv'\n",
    "\n",
    "data = process_files(folder_path)\n",
    "create_csv(data, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file created: comprehensive_predictions_summary_4.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'comprehensive_predictions_summary_4.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function to extract mean value from the string\n",
    "def extract_mean(value):\n",
    "    return float(value.split(' ± ')[0])\n",
    "\n",
    "# Apply the function to relevant columns to get mean values\n",
    "data['Accuracy_mean'] = data['Accuracy'].apply(extract_mean)\n",
    "data['Prediction_Size_90_mean'] = data['Prediction Size (90% Coverage)'].apply(extract_mean)\n",
    "data['Coverage_90_mean'] = data['90% Coverage'].apply(extract_mean)\n",
    "\n",
    "# Save the updated CSV\n",
    "updated_file_path = 'comprehensive_predictions_summary_4.csv'\n",
    "data.to_csv(updated_file_path, index=False)\n",
    "print(f\"Updated CSV file created: {updated_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bellow code is for separate columns with only mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file created: comprehensive_predictions_summary_3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'comprehensive_predictions_summary_3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function to extract mean value from the string\n",
    "def extract_mean(value):\n",
    "    return float(value.split(' ± ')[0])\n",
    "\n",
    "# Apply the function to relevant columns to get mean values\n",
    "data['Accuracy_mean'] = data['Accuracy'].apply(extract_mean)\n",
    "data['Prediction_Size_90_mean'] = data['Prediction Size (90% Coverage)'].apply(extract_mean)\n",
    "data['Coverage_90_mean'] = data['90% Coverage'].apply(extract_mean)\n",
    "\n",
    "# Save the updated CSV\n",
    "updated_file_path = 'comprehensive_predictions_summary_3.csv'\n",
    "data.to_csv(updated_file_path, index=False)\n",
    "print(f\"Updated CSV file created: {updated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created: comprehensive_predictions_summary_4.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_values(line):\n",
    "    pattern = r\"Result: \\((\\d+), \\{'Accuracy': ([\\d.]+), 'APS': \\(([\\d.]+), ([\\d.]+)\\), 'APSeps05': \\(([\\d.]+), ([\\d.]+)\\)\\}\\)\"\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        result_num = int(match.group(1))\n",
    "        accuracy = float(match.group(2))\n",
    "        coverage_90 = float(match.group(3))\n",
    "        aps_score = float(match.group(4))\n",
    "        coverage_95 = float(match.group(5))\n",
    "        apseps05_score = float(match.group(6))\n",
    "        return result_num, accuracy, coverage_90, aps_score, coverage_95, apseps05_score\n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract values from line: {line}\")\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.replace('.txt', '').split('_')\n",
    "    \n",
    "    # Determine if the dataset is biased or unbiased\n",
    "    dataset_type = 'biased' if 'train' in parts else 'unbiased'\n",
    "    \n",
    "    data = {\n",
    "        'dataset_type': dataset_type,\n",
    "        'dataset': '',\n",
    "        'model': '',\n",
    "        'conformal_score': '',\n",
    "        'method': 'CE',  # Default method\n",
    "        'alpha_bias': '0.1' if dataset_type == 'biased' else '1.0',  # Default for biased datasets if not specified\n",
    "        'ld1': '0',  # Default value for ld1\n",
    "        'ld2': '0'  # Default value for ld2\n",
    "    }\n",
    "    \n",
    "    for i, part in enumerate(parts):\n",
    "        if part in ['cora', 'citeseer', 'PubMed']:\n",
    "            data['dataset'] = part\n",
    "        elif part in ['APPNP', 'GAT', 'GCN', 'GraphSAGE', 'DAGNN']:\n",
    "            data['model'] = part\n",
    "        elif part in ['aps', 'raps']:\n",
    "            data['conformal_score'] = part\n",
    "        elif part in ['SRGNN', 'cmd', 'MMD','CEMD', 'CKLJS','CKLJSEM', 'CKL', 'CJS','kld', 'jsd', 'emd', 'CE']:\n",
    "            data['method'] = part\n",
    "        elif part == 'alpha' and i + 1 < len(parts) and parts[i + 1] == 'bias':\n",
    "            data['alpha_bias'] = parts[i + 2]\n",
    "        elif part == 'ld1' and i + 1 < len(parts):\n",
    "            data['ld1'] = parts[i + 1]\n",
    "        elif part == 'ld2' and i + 1 < len(parts):\n",
    "            data['ld2'] = parts[i + 1]\n",
    "    \n",
    "    # Override the default alpha_bias if explicitly mentioned in the filename\n",
    "    for part in parts:\n",
    "        if part in ['0.2', '0.4', '0.6'] and dataset_type == 'biased':\n",
    "            data['alpha_bias'] = part\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_files(folder_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                lines = content.strip().split('\\n')\n",
    "                values = [extract_values(line) for line in lines if line.strip()]\n",
    "                \n",
    "                if values:\n",
    "                    _, *metric_values = zip(*values)\n",
    "                    means = np.mean(metric_values, axis=1)\n",
    "                    stds = np.std(metric_values, axis=1)\n",
    "                    result = [f\"{mean:.4f} ± {std:.4f}\" for mean, std in zip(means, stds)]\n",
    "                    \n",
    "                    file_info = parse_filename(filename)\n",
    "                    data.append(list(file_info.values()) + result)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_csv(data, output_file):\n",
    "    columns = ['Dataset Type', 'Dataset', 'Model', 'Conformal Score', 'Method', 'Alpha Bias', 'LD1', 'LD2',\n",
    "               'Accuracy', '90% Coverage', 'Prediction Size (90% Coverage)', '95% Coverage', 'Prediction Size (95% Coverage)']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"CSV file created: {output_file}\")\n",
    "\n",
    "# Usage\n",
    "folder_path = r'D:\\csr\\CondSR\\pred'  # Using raw string for Windows path\n",
    "output_file = 'comprehensive_predictions_summary_4.csv'\n",
    "\n",
    "data = process_files(folder_path)\n",
    "create_csv(data, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file created: comprehensive_predictions_summary_citeseer.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'comprehensive_predictions_summary_citeseer.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function to extract mean value from the string\n",
    "def extract_mean(value):\n",
    "    return float(value.split(' ± ')[0])\n",
    "\n",
    "# Apply the function to relevant columns to get mean values\n",
    "data['Accuracy_mean'] = data['Accuracy'].apply(extract_mean)\n",
    "data['Prediction_Size_90_mean'] = data['Prediction Size (90% Coverage)'].apply(extract_mean)\n",
    "data['Coverage_90_mean'] = data['90% Coverage'].apply(extract_mean)\n",
    "\n",
    "# Save the updated CSV\n",
    "updated_file_path = 'comprehensive_predictions_summary_citeseer.csv'\n",
    "data.to_csv(updated_file_path, index=False)\n",
    "print(f\"Updated CSV file created: {updated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy (Method)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy_method\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy_method\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m↑\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImprovement (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m↓\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImprovement (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Pivot the table to have methods as columns\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m pivot_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMethod_method\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAccuracy (Method)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Add IID and Biased (CE) columns\u001b[39;00m\n\u001b[0;32m     28\u001b[0m pivot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIID Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m iid_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:9339\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[1;34m(self, columns, index, values)\u001b[0m\n\u001b[0;32m   9332\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   9333\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   9334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\n\u001b[0;32m   9335\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m   9336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   9337\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[1;32m-> 9339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:570\u001b[0m, in \u001b[0;36mpivot\u001b[1;34m(data, columns, index, values)\u001b[0m\n\u001b[0;32m    566\u001b[0m         indexed \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_constructor_sliced(data[values]\u001b[38;5;241m.\u001b[39m_values, index\u001b[38;5;241m=\u001b[39mmultiindex)\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"unstack\" of \"DataFrame\" has incompatible type \"Union\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# [List[Any], ExtensionArray, ndarray[Any, Any], Index, Series]\"; expected\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# \"Hashable\"\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mindexed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_listlike\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    571\u001b[0m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    572\u001b[0m     name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m    573\u001b[0m ]\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\series.py:4615\u001b[0m, in \u001b[0;36mSeries.unstack\u001b[1;34m(self, level, fill_value, sort)\u001b[0m\n\u001b[0;32m   4570\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4571\u001b[0m \u001b[38;5;124;03mUnstack, also known as pivot, Series with MultiIndex to produce DataFrame.\u001b[39;00m\n\u001b[0;32m   4572\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4611\u001b[0m \u001b[38;5;124;03mb    2    4\u001b[39;00m\n\u001b[0;32m   4612\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4613\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unstack\n\u001b[1;32m-> 4615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:517\u001b[0m, in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value, sort)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(obj\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unstack_extension_series(obj, level, fill_value, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[1;32m--> 517\u001b[0m unstacker \u001b[38;5;241m=\u001b[39m \u001b[43m_Unstacker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor_expanddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unstacker\u001b[38;5;241m.\u001b[39mget_result(\n\u001b[0;32m    521\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_values, value_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m    522\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:154\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[1;34m(self, index, level, constructor, sort)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_cells \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:\n\u001b[0;32m    147\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following operation may generate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cells\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cells \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the resulting pandas object.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    150\u001b[0m         PerformanceWarning,\n\u001b[0;32m    151\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    152\u001b[0m     )\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_selectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:210\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m mask\u001b[38;5;241m.\u001b[39mput(selector, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex contains duplicate entries, cannot reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_index \u001b[38;5;241m=\u001b[39m comp_index\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m mask\n",
      "\u001b[1;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('comprehensive_predictions_summary_4.csv')\n",
    "\n",
    "# Filter the data to include only the relevant columns\n",
    "df = df[['Dataset Type', 'Model', 'Method', 'Accuracy', 'Accuracy_mean']]\n",
    "\n",
    "# Separate the unbiased (IID), biased (CE), and other methods\n",
    "iid_df = df[df['Dataset Type'] == 'unbiased']\n",
    "biased_ce_df = df[(df['Dataset Type'] == 'biased') & (df['Method'] == 'biased(CE)')]\n",
    "methods_df = df[(df['Dataset Type'] == 'biased') & (df['Method'] != 'biased(CE)')]\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_df = pd.merge(methods_df, biased_ce_df, on='Model', suffixes=('_method', '_biased_ce'))\n",
    "merged_df = pd.merge(merged_df, iid_df, on='Model', suffixes=('', '_iid'))\n",
    "\n",
    "# Calculate the percentage improvement compared to Biased (CE)\n",
    "merged_df['Improvement (%)'] = ((merged_df['Accuracy_mean_method'] - merged_df['Accuracy_mean_biased_ce']) / merged_df['Accuracy_mean_biased_ce']) * 100\n",
    "\n",
    "# Format the accuracy and improvement\n",
    "merged_df['Accuracy (Method)'] = merged_df.apply(lambda x: f\"{x['Accuracy_method'].split(' ± ')[0]} ± {x['Accuracy_method'].split(' ± ')[1]} ({'↑' if x['Improvement (%)'] > 0 else '↓'} {abs(x['Improvement (%)']):.2f}%)\", axis=1)\n",
    "\n",
    "# Pivot the table to have methods as columns\n",
    "pivot_df = merged_df.pivot(index='Model', columns='Method_method', values='Accuracy (Method)')\n",
    "\n",
    "# Add IID and Biased (CE) columns\n",
    "pivot_df['IID Accuracy'] = iid_df.set_index('Model')['Accuracy'].apply(lambda x: f\"{x.split(' ± ')[0]}\")\n",
    "pivot_df['Biased (CE) Accuracy'] = biased_ce_df.set_index('Model')['Accuracy'].apply(lambda x: f\"{x.split(' ± ')[0]}\")\n",
    "\n",
    "# Reorder columns\n",
    "pivot_df = pivot_df[['IID Accuracy', 'Biased (CE) Accuracy'] + list(pivot_df.columns[:-2])]\n",
    "\n",
    "# Display the final table\n",
    "print(pivot_df)\n",
    "\n",
    "# Optionally, save the table to a CSV file for further use\n",
    "pivot_df.to_csv('accuracy_comparison_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6548\u001b[0m ):\n\u001b[1;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12422\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert string 'biasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiasedbiased' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merged_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMethod_method\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mduplicated()\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Handle duplicates by grouping and aggregating (e.g., using mean for numeric columns)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMethod_method\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate the percentage improvement compared to Biased (CE)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImprovement (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     25\u001b[0m     (merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy_mean_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy_mean_biased_ce\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;241m/\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy_mean_biased_ce\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     27\u001b[0m ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2446\u001b[0m         grouped_mean,\n\u001b[0;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2448\u001b[0m         engine_kwargs,\n\u001b[0;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2450\u001b[0m     )\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1469\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1469\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43msb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1470\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\amite\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('comprehensive_predictions_summary_4.csv')\n",
    "\n",
    "# Filter the data to include only the relevant columns\n",
    "df = df[['Dataset Type', 'Model', 'Method', 'Accuracy', 'Accuracy_mean']]\n",
    "\n",
    "# Separate the unbiased (IID), biased (CE), and other methods\n",
    "iid_df = df[df['Dataset Type'] == 'unbiased']\n",
    "biased_ce_df = df[(df['Dataset Type'] == 'biased') & (df['Method'] == 'biased(CE)')]\n",
    "methods_df = df[(df['Dataset Type'] == 'biased') & (df['Method'] != 'biased(CE)')]\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_df = pd.merge(methods_df, biased_ce_df, on='Model', suffixes=('_method', '_biased_ce'))\n",
    "merged_df = pd.merge(merged_df, iid_df, on='Model', suffixes=('', '_iid'))\n",
    "\n",
    "# Check for duplicates\n",
    "if merged_df[['Model', 'Method_method']].duplicated().any():\n",
    "    # Handle duplicates by grouping and aggregating (e.g., using mean for numeric columns)\n",
    "    merged_df = merged_df.groupby(['Model', 'Method_method'], as_index=False).mean()\n",
    "\n",
    "# Calculate the percentage improvement compared to Biased (CE)\n",
    "merged_df['Improvement (%)'] = (\n",
    "    (merged_df['Accuracy_mean_method'] - merged_df['Accuracy_mean_biased_ce'])\n",
    "    / merged_df['Accuracy_mean_biased_ce']\n",
    ") * 100\n",
    "\n",
    "# Format the accuracy and improvement\n",
    "merged_df['Accuracy (Method)'] = merged_df.apply(\n",
    "    lambda x: f\"{x['Accuracy_method'].split(' ± ')[0]} ± {x['Accuracy_method'].split(' ± ')[1]} \"\n",
    "              f\"({'↑' if x['Improvement (%)'] > 0 else '↓'} {abs(x['Improvement (%)']):.2f}%)\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Pivot the table to have methods as columns\n",
    "pivot_df = merged_df.pivot(index='Model', columns='Method_method', values='Accuracy (Method)')\n",
    "\n",
    "# Add IID and Biased (CE) columns\n",
    "pivot_df['IID Accuracy'] = iid_df.set_index('Model')['Accuracy'].apply(lambda x: f\"{x.split(' ± ')[0]}\")\n",
    "pivot_df['Biased (CE) Accuracy'] = biased_ce_df.set_index('Model')['Accuracy'].apply(lambda x: f\"{x.split(' ± ')[0]}\")\n",
    "\n",
    "# Reorder columns\n",
    "pivot_df = pivot_df[['IID Accuracy', 'Biased (CE) Accuracy'] + list(pivot_df.columns[:-2])]\n",
    "\n",
    "# Display the final table\n",
    "print(pivot_df)\n",
    "\n",
    "# Save the table to a CSV file for further use\n",
    "pivot_df.to_csv('accuracy_comparison_table.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method_method IID Accuracy Biased (CE) Accuracy                        CJS  \\\n",
      "Model                                                                        \n",
      "APPNP               0.8562               0.7101  0.7278 ± 0.0214 (↑ 2.49%)   \n",
      "DAGNN               0.8229               0.7179  0.7232 ± 0.0181 (↑ 0.74%)   \n",
      "GAT                 0.8080               0.6861  0.6771 ± 0.0313 (↓ 1.31%)   \n",
      "GCN                 0.7991               0.6675  0.6780 ± 0.0045 (↑ 1.57%)   \n",
      "GraphSAGE           0.8084               0.6924  0.7344 ± 0.0101 (↑ 6.07%)   \n",
      "\n",
      "Method_method                        CKL                        MMD  \\\n",
      "Model                                                                 \n",
      "APPNP          0.7318 ± 0.0219 (↑ 3.06%)  0.7175 ± 0.0163 (↑ 1.04%)   \n",
      "DAGNN          0.7345 ± 0.0113 (↑ 2.31%)  0.7187 ± 0.0020 (↑ 0.11%)   \n",
      "GAT            0.6847 ± 0.0295 (↓ 0.20%)  0.6801 ± 0.0147 (↓ 0.87%)   \n",
      "GCN            0.6812 ± 0.0050 (↑ 2.05%)  0.6672 ± 0.0069 (↓ 0.04%)   \n",
      "GraphSAGE      0.7282 ± 0.0125 (↑ 5.17%)  0.6888 ± 0.0096 (↓ 0.52%)   \n",
      "\n",
      "Method_method                      SRGNN                        cmd  \\\n",
      "Model                                                                 \n",
      "APPNP          0.7530 ± 0.0187 (↑ 6.04%)  0.7304 ± 0.0170 (↑ 2.86%)   \n",
      "DAGNN          0.7312 ± 0.0125 (↑ 1.85%)  0.7305 ± 0.0121 (↑ 1.76%)   \n",
      "GAT            0.6798 ± 0.0340 (↓ 0.92%)  0.6773 ± 0.0318 (↓ 1.28%)   \n",
      "GCN            0.6801 ± 0.0077 (↑ 1.89%)  0.6758 ± 0.0072 (↑ 1.24%)   \n",
      "GraphSAGE      0.7333 ± 0.0116 (↑ 5.91%)  0.7357 ± 0.0120 (↑ 6.25%)   \n",
      "\n",
      "Method_method                        jsd                        kld  \n",
      "Model                                                                \n",
      "APPNP          0.7094 ± 0.0211 (↓ 0.10%)  0.7202 ± 0.0126 (↑ 1.42%)  \n",
      "DAGNN          0.7173 ± 0.0021 (↓ 0.08%)  0.7175 ± 0.0033 (↓ 0.06%)  \n",
      "GAT            0.6905 ± 0.0168 (↑ 0.64%)  0.6846 ± 0.0097 (↓ 0.22%)  \n",
      "GCN            0.6663 ± 0.0055 (↓ 0.18%)  0.6680 ± 0.0072 (↑ 0.07%)  \n",
      "GraphSAGE      0.6913 ± 0.0155 (↓ 0.16%)  0.6878 ± 0.0064 (↓ 0.66%)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('comprehensive_predictions_summary_4.csv')\n",
    "\n",
    "# Filter the data to include only the relevant columns\n",
    "df = df[['Dataset Type', 'Model', 'Method', 'Accuracy', 'Accuracy_mean']]\n",
    "\n",
    "# Separate the unbiased (IID), biased (CE), and other methods\n",
    "iid_df = df[df['Dataset Type'] == 'unbiased']\n",
    "biased_ce_df = df[(df['Dataset Type'] == 'biased') & (df['Method'] == 'biased(CE)')]\n",
    "methods_df = df[(df['Dataset Type'] == 'biased') & (df['Method'] != 'biased(CE)')]\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_df = pd.merge(methods_df, biased_ce_df, on='Model', suffixes=('_method', '_biased_ce'))\n",
    "merged_df = pd.merge(merged_df, iid_df, on='Model', suffixes=('', '_iid'))\n",
    "\n",
    "# Drop duplicate rows\n",
    "merged_df = merged_df.drop_duplicates(subset=['Model', 'Method_method'])\n",
    "\n",
    "# Calculate the percentage improvement compared to Biased (CE)\n",
    "merged_df['Improvement (%)'] = (\n",
    "    (merged_df['Accuracy_mean_method'] - merged_df['Accuracy_mean_biased_ce'])\n",
    "    / merged_df['Accuracy_mean_biased_ce']\n",
    ") * 100\n",
    "\n",
    "# Format the accuracy and improvement\n",
    "merged_df['Accuracy (Method)'] = merged_df.apply(\n",
    "    lambda x: f\"{x['Accuracy_method'].split(' ± ')[0]} ± {x['Accuracy_method'].split(' ± ')[1]} \"\n",
    "              f\"({'↑' if x['Improvement (%)'] > 0 else '↓'} {abs(x['Improvement (%)']):.2f}%)\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Pivot the table to have methods as columns\n",
    "pivot_df = merged_df.pivot(index='Model', columns='Method_method', values='Accuracy (Method)')\n",
    "\n",
    "# Add IID and Biased (CE) columns\n",
    "pivot_df['IID Accuracy'] = iid_df.set_index('Model')['Accuracy'].apply(lambda x: f\"{x.split(' ± ')[0]}\")\n",
    "pivot_df['Biased (CE) Accuracy'] = biased_ce_df.set_index('Model')['Accuracy'].apply(lambda x: f\"{x.split(' ± ')[0]}\")\n",
    "\n",
    "# Reorder columns\n",
    "pivot_df = pivot_df[['IID Accuracy', 'Biased (CE) Accuracy'] + list(pivot_df.columns[:-2])]\n",
    "\n",
    "# Display the final table\n",
    "print(pivot_df)\n",
    "\n",
    "# Save the table to a CSV file for further use\n",
    "pivot_df.to_csv('accuracy_comparison_table_cora.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison CSV file saved: comprehensive_coverage_comparison_citeseer.csv\n",
      "\n",
      "First few rows of the comparison table:\n",
      "Method     IID Coverage  Biased (CE) Coverage               CJS  \\\n",
      "Model                                                             \n",
      "APPNP            0.9007                0.9022  0.9020 (↓ 0.02%)   \n",
      "DAGNN            0.9020                0.9029  0.9021 (↓ 0.09%)   \n",
      "GAT              0.9011                0.9013  0.9021 (↑ 0.09%)   \n",
      "GCN              0.9009                0.9031  0.9029 (↓ 0.02%)   \n",
      "GraphSAGE        0.9004                0.9015  0.9018 (↑ 0.03%)   \n",
      "\n",
      "Method                  CKL               MMD             SRGNN  \\\n",
      "Model                                                             \n",
      "APPNP      0.9019 (↓ 0.03%)  0.9023 (↑ 0.01%)  0.9025 (↑ 0.03%)   \n",
      "DAGNN      0.9019 (↓ 0.11%)  0.9024 (↓ 0.06%)  0.9017 (↓ 0.13%)   \n",
      "GAT        0.9023 (↑ 0.11%)  0.9015 (↑ 0.02%)  0.9018 (↑ 0.06%)   \n",
      "GCN        0.9030 (↓ 0.01%)  0.9033 (↑ 0.02%)  0.9028 (↓ 0.03%)   \n",
      "GraphSAGE  0.9016 (↑ 0.01%)  0.9014 (↓ 0.01%)  0.9022 (↑ 0.08%)   \n",
      "\n",
      "Method                  cmd               jsd               kld  \n",
      "Model                                                            \n",
      "APPNP      0.9020 (↓ 0.02%)  0.9025 (↑ 0.03%)  0.9018 (↓ 0.04%)  \n",
      "DAGNN      0.9021 (↓ 0.09%)  0.9030 (↑ 0.01%)  0.9029 (↓ 0.00%)  \n",
      "GAT        0.9019 (↑ 0.07%)  0.9016 (↑ 0.03%)  0.9016 (↑ 0.03%)  \n",
      "GCN        0.9030 (↓ 0.01%)  0.9031 (↓ 0.00%)  0.9031 (↓ 0.00%)  \n",
      "GraphSAGE  0.9022 (↑ 0.08%)  0.9015 (↓ 0.00%)  0.9015 (↓ 0.00%)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('comprehensive_predictions_summary_citeseer.csv')\n",
    "\n",
    "# First, let's verify we have all required columns\n",
    "required_columns = ['Model', 'Method', '90% Coverage']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    raise ValueError(f\"Missing required columns: {', '.join(set(required_columns) - set(df.columns))}\")\n",
    "\n",
    "# Convert '90% Coverage' to numeric, removing any non-numeric characters\n",
    "df['90% Coverage'] = df['90% Coverage'].str.extract(r'([\\d.]+)').astype(float)\n",
    "\n",
    "# Separate data by method types\n",
    "iid_df = df[df['Method'] == 'IID'].copy()\n",
    "biased_df = df[df['Method'] == 'biased(CE)'].copy()\n",
    "methods_df = df[~df['Method'].isin(['IID', 'biased(CE)'])].copy()\n",
    "\n",
    "# First merge: methods with IID\n",
    "temp_df = methods_df.merge(\n",
    "    iid_df[['Model', '90% Coverage']].rename(columns={'90% Coverage': 'Coverage_IID'}),\n",
    "    on='Model'\n",
    ")\n",
    "\n",
    "# Second merge: add biased results\n",
    "merged_df = temp_df.merge(\n",
    "    biased_df[['Model', '90% Coverage']].rename(columns={'90% Coverage': 'Coverage_Biased'}),\n",
    "    on='Model'\n",
    ")\n",
    "\n",
    "# Calculate improvement percentage\n",
    "merged_df['Improvement (%)'] = (\n",
    "    (merged_df['90% Coverage'] - merged_df['Coverage_Biased']) /\n",
    "    merged_df['Coverage_Biased']\n",
    ") * 100\n",
    "\n",
    "# Format the comparison string\n",
    "merged_df['Coverage (Method)'] = merged_df.apply(\n",
    "    lambda x: f\"{x['90% Coverage']:.4f} ({'↑' if x['Improvement (%)'] > 0 else '↓'} {abs(x['Improvement (%)']):.2f}%)\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop duplicates to ensure uniqueness before pivoting\n",
    "merged_df = merged_df.drop_duplicates(subset=['Model', 'Method'])\n",
    "\n",
    "# Create pivot table\n",
    "pivot_df = merged_df.pivot(\n",
    "    index='Model',\n",
    "    columns='Method',\n",
    "    values='Coverage (Method)'\n",
    ")\n",
    "\n",
    "# Add IID and Biased (CE) coverage columns\n",
    "pivot_df['IID Coverage'] = iid_df.set_index('Model')['90% Coverage']\n",
    "pivot_df['Biased (CE) Coverage'] = biased_df.set_index('Model')['90% Coverage']\n",
    "\n",
    "# Reorder columns to put IID and Biased (CE) first\n",
    "cols = pivot_df.columns.tolist()\n",
    "cols = ['IID Coverage', 'Biased (CE) Coverage'] + [c for c in cols if c not in ['IID Coverage', 'Biased (CE) Coverage']]\n",
    "pivot_df = pivot_df[cols]\n",
    "\n",
    "# Save the final output\n",
    "pivot_df.to_csv('comprehensive_coverage_comparison_citeseer.csv')\n",
    "print(\"Comparison CSV file saved: comprehensive_coverage_comparison_citeseer.csv\")\n",
    "\n",
    "# Display first few rows of the pivot table\n",
    "print(\"\\nFirst few rows of the comparison table:\")\n",
    "print(pivot_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison CSV file saved: comprehensive_Prediction Size (90% Coverage)_comparison_cora.csv\n",
      "\n",
      "First few rows of the comparison table:\n",
      "Method     IID Prediction Size (90% Coverage)  \\\n",
      "Model                                           \n",
      "APPNP                                  3.8159   \n",
      "DAGNN                                  4.5173   \n",
      "GAT                                    3.4103   \n",
      "GCN                                    3.8876   \n",
      "GraphSAGE                              3.3313   \n",
      "\n",
      "Method     Biased (CE) Prediction Size (90% Coverage)                CJS  \\\n",
      "Model                                                                      \n",
      "APPNP                                          4.1407  2.2595 (↓ 45.43%)   \n",
      "DAGNN                                          4.7468  3.2271 (↓ 32.02%)   \n",
      "GAT                                            3.9805  2.7659 (↓ 30.51%)   \n",
      "GCN                                            4.1933   4.1019 (↓ 2.18%)   \n",
      "GraphSAGE                                      3.6772  2.1970 (↓ 40.25%)   \n",
      "\n",
      "Method                   CKL               MMD              SRGNN  \\\n",
      "Model                                                               \n",
      "APPNP      2.3306 (↓ 43.71%)  4.0549 (↓ 2.07%)  2.3003 (↓ 44.45%)   \n",
      "DAGNN      3.3076 (↓ 30.32%)  4.7400 (↓ 0.14%)  3.2751 (↓ 31.00%)   \n",
      "GAT        2.6841 (↓ 32.57%)  4.0488 (↑ 1.72%)  2.7158 (↓ 31.77%)   \n",
      "GCN         4.1097 (↓ 1.99%)  4.2021 (↑ 0.21%)   4.1070 (↓ 2.06%)   \n",
      "GraphSAGE  2.2793 (↓ 38.02%)  3.5620 (↓ 3.13%)  2.2125 (↓ 39.83%)   \n",
      "\n",
      "Method                   cmd               jsd               kld  \n",
      "Model                                                             \n",
      "APPNP      2.3256 (↓ 43.84%)  4.1400 (↓ 0.02%)  4.0595 (↓ 1.96%)  \n",
      "DAGNN      3.2262 (↓ 32.03%)  4.7476 (↑ 0.02%)  4.7476 (↑ 0.02%)  \n",
      "GAT        2.7569 (↓ 30.74%)  3.9182 (↓ 1.57%)  3.9774 (↓ 0.08%)  \n",
      "GCN         4.1287 (↓ 1.54%)  4.2187 (↑ 0.61%)  4.2011 (↑ 0.19%)  \n",
      "GraphSAGE  2.1734 (↓ 40.90%)  3.5411 (↓ 3.70%)  3.7013 (↑ 0.66%)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('comprehensive_predictions_summary_4.csv')\n",
    "\n",
    "# First, let's verify we have all required columns\n",
    "required_columns = ['Model', 'Method', 'Prediction Size (90% Coverage)']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    raise ValueError(f\"Missing required columns: {', '.join(set(required_columns) - set(df.columns))}\")\n",
    "\n",
    "# Convert '90% Coverage' to numeric, removing any non-numeric characters\n",
    "df['Prediction Size (90% Coverage)'] = df['Prediction Size (90% Coverage)'].str.extract(r'([\\d.]+)').astype(float)\n",
    "\n",
    "# Separate data by method types\n",
    "iid_df = df[df['Method'] == 'IID'].copy()\n",
    "biased_df = df[df['Method'] == 'biased(CE)'].copy()\n",
    "methods_df = df[~df['Method'].isin(['IID', 'biased(CE)'])].copy()\n",
    "\n",
    "# First merge: methods with IID\n",
    "temp_df = methods_df.merge(\n",
    "    iid_df[['Model', 'Prediction Size (90% Coverage)']].rename(columns={'Prediction Size (90% Coverage)': 'Prediction Size (90% Coverage)_IID'}),\n",
    "    on='Model'\n",
    ")\n",
    "\n",
    "# Second merge: add biased results\n",
    "merged_df = temp_df.merge(\n",
    "    biased_df[['Model', 'Prediction Size (90% Coverage)']].rename(columns={'Prediction Size (90% Coverage)': 'Prediction Size (90% Coverage)_Biased'}),\n",
    "    on='Model'\n",
    ")\n",
    "\n",
    "# Calculate improvement percentage\n",
    "merged_df['Improvement (%)'] = (\n",
    "    (merged_df['Prediction Size (90% Coverage)'] - merged_df['Prediction Size (90% Coverage)_Biased']) /\n",
    "    merged_df['Prediction Size (90% Coverage)_Biased']\n",
    ") * 100\n",
    "\n",
    "# Format the comparison string\n",
    "merged_df['Prediction Size (90% Coverage) (Method)'] = merged_df.apply(\n",
    "    lambda x: f\"{x['Prediction Size (90% Coverage)']:.4f} ({'↑' if x['Improvement (%)'] > 0 else '↓'} {abs(x['Improvement (%)']):.2f}%)\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop duplicates to ensure uniqueness before pivoting\n",
    "merged_df = merged_df.drop_duplicates(subset=['Model', 'Method'])\n",
    "\n",
    "# Create pivot table\n",
    "pivot_df = merged_df.pivot(\n",
    "    index='Model',\n",
    "    columns='Method',\n",
    "    values='Prediction Size (90% Coverage) (Method)'\n",
    ")\n",
    "\n",
    "# Add IID and Biased (CE) coverage columns\n",
    "pivot_df['IID Prediction Size (90% Coverage)'] = iid_df.set_index('Model')['Prediction Size (90% Coverage)']\n",
    "pivot_df['Biased (CE) Prediction Size (90% Coverage)'] = biased_df.set_index('Model')['Prediction Size (90% Coverage)']\n",
    "\n",
    "# Reorder columns to put IID and Biased (CE) first\n",
    "cols = pivot_df.columns.tolist()\n",
    "cols = ['IID Prediction Size (90% Coverage)', 'Biased (CE) Prediction Size (90% Coverage)'] + [c for c in cols if c not in ['IID Prediction Size (90% Coverage)', 'Biased (CE) Prediction Size (90% Coverage)']]\n",
    "pivot_df = pivot_df[cols]\n",
    "\n",
    "# Save the final output\n",
    "pivot_df.to_csv('comprehensive_Prediction Size (90% Coverage)_comparison_cora.csv')\n",
    "print(\"Comparison CSV file saved: comprehensive_Prediction Size (90% Coverage)_comparison_cora.csv\")\n",
    "\n",
    "# Display first few rows of the pivot table\n",
    "print(\"\\nFirst few rows of the comparison table:\")\n",
    "print(pivot_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
